## data
train_file: /workspace/mnt2/dpr_datasets/downloads/data/retriever/nq-train.json
dev_file: /workspace/mnt2/dpr_datasets/downloads/data/retriever/nq-dev.json


## training
base_model: bert-base-uncased
per_device_train_batch_size: 32
per_device_eval_batch_size: 8
adam_eps: 1.0e-8
weight_decay: 0.0
max_grad_norm: 2.0
lr: 2.0e-5
warmup_steps: 1237
max_train_epochs: 40
seed: 19980406
gradient_accumulation_steps: 4
num_hard_negative_ctx: 30
num_other_negative_ctx: 30
vram_fraction: 0.3 # 24GB / 80GB

## logs
log_dir : /workspace/mnt2/dpr_logs
embed_dir : /workspace/mnt2/dpr_output/
run_name : MDF_nq_contAccum_bsz32_cache8_accum4

## loss (Contrastive Accumulation)
prev_cache : True
cont_cache : True
cache_query : True
cache_hard_neg : True
cache_size : 8
use_hard_neg : True