{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir import util\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from tqdm.autonotebook import tqdm\n",
    "import os, gzip, json\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. download hard negative passages of msmarco mined by sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_url = \"https://sbert.net/datasets/msmarco-hard-negatives.jsonl.gz\"\n",
    "data_path = \"/workspace/mnt2/dpr_datasets/msmarco/sbert\"\n",
    "msmarco_triplets_filepath = os.path.join(data_path, \"msmarco-hard-negatives.jsonl.gz\")\n",
    "if not os.path.isfile(msmarco_triplets_filepath):\n",
    "    util.download_url(triplets_url, msmarco_triplets_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"msmarco\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = \"/workspace/mnt2/dpr_datasets/msmarco/beir/msmarco\"\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "corpus, queries, _ = GenericDataLoader(data_path).load(split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. select the hard negative passages which has cross encoder score lower than positive passages - 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_score_margin = 3\n",
    "num_negs_per_system = 10\n",
    "train_queries = {}\n",
    "not_selected_samples = []\n",
    "cnt=0\n",
    "with gzip.open(msmarco_triplets_filepath, 'rt', encoding='utf8') as fIn:\n",
    "    for line in tqdm(fIn, total=502939):\n",
    "        not_selected_samples.append(cnt)\n",
    "        cnt = 0\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        #Get the positive passage ids\n",
    "        pos_pids = [item['pid'] for item in data['pos']]\n",
    "        pos_min_ce_score = min([item['ce-score'] for item in data['pos']])\n",
    "        ce_score_threshold = pos_min_ce_score - ce_score_margin\n",
    "        \n",
    "        #Get the hard negatives\n",
    "        neg_pids = set()\n",
    "\n",
    "        if 'bm25' not in data['neg']:\n",
    "            continue\n",
    "        system_negs = data['neg']['bm25']\n",
    "        negs_added = 0\n",
    "        for item in system_negs:\n",
    "            if item['ce-score'] > ce_score_threshold:\n",
    "                cnt += 1\n",
    "                continue\n",
    "\n",
    "            pid = item['pid']\n",
    "            if pid not in neg_pids:\n",
    "                neg_pids.add(pid)\n",
    "                negs_added += 1\n",
    "                if negs_added >= num_negs_per_system:\n",
    "                    break\n",
    "        \n",
    "        if len(pos_pids) > 0 and len(neg_pids) > 0:\n",
    "            train_queries[data['qid']] = {\n",
    "                'query': queries[data['qid']], \n",
    "                'pos': pos_pids, \n",
    "                'hard_neg': list(neg_pids)}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess the hard negative passages with the original msmarco data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it took more than 40 minutes to download the dataset\n",
    "corpus = load_dataset('BeIR/msmarco', 'corpus', cache_dir='/workspace/mnt2/dpr_datasets/msmarco/original')\n",
    "query = load_dataset('BeIR/msmarco', 'queries', cache_dir='/workspace/mnt2/dpr_datasets/msmarco/original')\n",
    "qrels = load_dataset('BeIR/msmarco-qrels', cache_dir='/workspace/mnt2/dpr_datasets/msmarco/original') # train/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {}\n",
    "\n",
    "for line in tqdm(query['queries']):\n",
    "    queries[line['_id']] = line\n",
    "\n",
    "corpus_ = {}\n",
    "\n",
    "for line in tqdm(corpus['corpus']):\n",
    "    corpus_[line['_id']] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco = []\n",
    "for qid, qrel in tqdm(train_queries.items()):\n",
    "    data = {}\n",
    "    data['dataset'] = 'msmarco'\n",
    "    data['question'] = {'text' : qrel['query']}\n",
    "    data['positive_ctxs'] = [corpus_[pid] for pid in qrel['pos']]\n",
    "    data['negative_ctxs'] = [corpus_[pid] for pid in qrel['hard_neg']]\n",
    "    msmarco.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/mnt2/dpr_datasets/msmarco/preprocessed/msmarco_train_filtered.json', 'w') as f:\n",
    "    json.dump(msmarco, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
